# -*- coding: utf-8 -*-
"""final-dicoding-incep-cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X7AvtApEOtYxJAkgCX66g0ReRdCN_asQ

# Intel Image Classification

By: Denny Alvito Ginting
dennyginting73@gmail.com

Acknowledge:
The dataset obtained from https://www.kaggle.com/datasets/puneet6060/intel-image-classification

## Importing Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import datetime
import tensorflow as tf
import keras
from keras.models import Sequential
from keras.layers import Dense, Activation, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D
from keras.preprocessing.image import ImageDataGenerator
from keras import regularizers
from keras import optimizers
from sklearn.metrics import f1_score
import keras.backend as K
from tensorflow import keras
import warnings
warnings.filterwarnings('ignore')
import pathlib

"""## Loading Dataset"""

train_dir = '../input/intel-image-classification/seg_train/seg_train'
train_classes = os.listdir(train_dir)
train_classes

"""## Creating Generator"""

size = 299
datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

train_generator = datagen.flow_from_directory(
    directory = train_dir,
    subset = 'training',
    batch_size = 128,
    seed = 42,
    class_mode = 'categorical',
    target_size = (size, size)
)

valid_generator=datagen.flow_from_directory(
      directory=train_dir,
      subset="validation",
      batch_size=128,
      seed=42,
      class_mode="categorical",
      target_size=(size, size)
)

"""## Modelling"""

tf.keras.backend.clear_session()
backbone_model = tf.keras.applications.InceptionResNetV2(
    include_top = False,
    weights = 'imagenet',
    input_shape=(size,size,3)
)
backbone_model.trainable = False

# tf.keras.backend.clear_session()
model = Sequential([
    backbone_model,
    Conv2D(16, (3,3), activation='relu'),
    MaxPooling2D(pool_size=(2,2)),
    Flatten(),
    Dense(16, activation='relu'),
    Dropout(0.5),
    Dense(6, activation='softmax')
])

model.summary()

checkpoint = tf.keras.callbacks.ModelCheckpoint('weights.hdf5', monitor= 'val_accuracy', save_best_only=True)

model.compile(tf.keras.optimizers.Adam(),loss="categorical_crossentropy",metrics=["accuracy"])

history = model.fit(
    train_generator,
    validation_data = valid_generator,
    epochs = 50,
    batch_size = 32,
    callbacks = [checkpoint],
    verbose = 1
)

fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (12,6))

ax[0].plot(history.history['accuracy'], '-', label = 'Training Accuracy')
ax[0].plot(history.history['val_accuracy'], '-', label = 'Validation Accuracy')
ax[0].set_xlabel('Epochs')
ax[0].set_ylabel('Accuracy')
ax[0].set_title('Epochs & Training Accuracy', fontsize=20)
ax[0].legend(loc='best')

ax[1].plot(history.history['loss'], '-', label = 'Training loss')
ax[1].plot(history.history['val_loss'], '-', label = 'Validation loss')
ax[1].set_xlabel('Epochs')
ax[1].set_ylabel('loss')
ax[1].set_title('Epochs & Training loss', fontsize=20)
ax[1].legend(loc='best')

plt.show()

"""## Evaluation"""

model.load_weights('weights.hdf5')

model.evaluate(valid_generator)

"""> By taking the best weight after training our model, our model can achieve a high score on validation data (92.6%)

## Deployment
"""

# Saving Model
export_directory = 'saved_model/'
tf.saved_model.save(model, export_directory)

# Converting to vegs.tflite
converter = tf.lite.TFLiteConverter.from_saved_model(export_directory)
tflite_model = converter.convert()

# Deploy
tflite_file = pathlib.Path('vegs.tflite')
tflite_file.write_bytes(tflite_model)

